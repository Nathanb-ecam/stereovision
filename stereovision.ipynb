{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereovision\n",
    "\n",
    "![Suzanne](main.png)\n",
    "\n",
    "Stereovision is a discipline that deals with the reconstruction of 3D information from images. For the reconstruction of a point, several images of this point are needed. These images must be taken from different points of view. The key step of the reconstruction, which is often problematic, is to identify the images of the point to be reconstructed in each view.\n",
    "\n",
    "## Epipolar Geometry\n",
    "\n",
    "Epipolar geometry involves two cameras. The epipolar geometry describes the geometric properties between two views of the same scene and depends only on the intrinsic parameters of the cameras and their relative positions. It provides, in particular, the epipolar constraint, which will be very useful to produce the matches between views.\n",
    "\n",
    "## The Fondamental Matrix\n",
    "\n",
    "![Epipolar Geometry - Sanyam Kapoor](epipolar.png)\n",
    "\n",
    "Let us imagine that we have two images, right and left, of the world space. Let's take a point $\\vec{x}$ in the right image space. The point $\\vec{X}$ of the world space, of which $\\vec{x}$ is the image, can be anywhere on the line passing through $\\vec{x}$ and the optical center of the right camera. We will call this line the back-projected ray of $\\vec{x}$. Let us note $\\vec{x}'$ the image of $\\vec{X}$ in the left image space. The locus of $\\vec{x}'$ is therefore the image line of the back-projected ray of $\\vec{x}$. This line is called the epipolar line and is denoted $\\vec{l}'$. The epipolar line passes through the epipole $\\vec{e}'$, image of the optical center of the right camera.\n",
    "\n",
    "In 2D projective geometry, a line with equation $ax+by+c = 0$ is represented by a vector with three components $(a, b, c)^T$ defined to within one factor. Thus, we have the following relationship:\n",
    "\n",
    ">The point $\\vec{x}$ belongs to the line $\\vec{l}$ if and only if $x^T\\vec{l} = 0$.\n",
    "\n",
    "Moreover, in 2D projective geometry, the following remarkable relations are valid:\n",
    "\n",
    "- The intersection of two lines $l$ and $l'$ is given by $x = l \\times l'$,\n",
    "- The line passing through two points $x$ and $x'$ is given by $l = x \\times x'$.\n",
    "\n",
    "Note that the vector product can be written as a product of matrix $x \\times y = [x]_\\times y$ where\n",
    "\n",
    "$$[x]_\\times = \\begin{pmatrix} 0 & −x3 & x2 \\\\ x3 & 0 & −x1 \\\\ −x2 & x1 & 0 \\end{pmatrix}$$\n",
    "\n",
    "To find the equation of the epipolar line in the left image space, we just need to find the coordinates of two points of this line. The first is the image $P'\\vec{C}$ of the optical center $\\vec{C}$ of the right camera where $P'$ is the projection matrix of the left camera. The second is $P'P^{+}\\vec{x}$ where $P^{+}$ is the pseudo inverse of the projection matrix $P$ of the right camera. The epipolar line thus has the equation $l' = [P'\\vec{C}]_\\times{}P'P^{+}\\vec{x} = F\\vec{x}$ with $F = [P'\\vec{C}]_\\times{}P'P^{+}$. $F$ is called fundamental matrix.\n",
    "\n",
    "Since the epipolar line $\\vec{l}' = F\\vec{x}$ is the locus of $\\vec{x}'$, $\\vec{x}'$ therefore belongs to $\\vec{l}'$ which leads to the epipolar constraint :\n",
    "\n",
    ">**The fundamental matrix is such that for any pair of points corresponding $\\vec{x} \\leftrightarrow \\vec{x}'$ in the two images, we have $\\vec{x}'^{T}F\\vec{x} = 0$.**\n",
    "\n",
    "## Computation of the fundamental matrix\n",
    "\n",
    "The fundamental matrix $F$ has seven degrees of freedom. It has nine components but these are defined to within one scale factor, which removes one degree of freedom. Moreover, the matrix $F$ is a singular matrix ($det(F) = 0$) which gives us seven degrees of freedom. So we need at least seven correspondences to compute $F$. The equation $x'^{T}_iFx_i = 0$ and the seven correspondences allow us to write a system of equations of the form $Af = 0$, where $f$ is the vector which contains the components of the matrix $F$. Let us assume that $A$ is a 7×9 matrix of rank 7. The general solution of $Af = 0$ can be written $\\alpha f_1 + (1-\\alpha) f_2$ where $f_1$ and $f_2$ are two particular independent solutions of $Af = 0$. We then use the singularity constraint $det(\\alpha F_1 + (1 - \\alpha)F_2) = 0$ to determine $\\alpha$. Since the singularity constraint gives rise to a third degree equation, we may have one or three solutions for $F$.\n",
    "\n",
    "## OpenCV\n",
    "\n",
    "In practice you will use the OpenCV library. In python, you have access to its functions through the `cv2` module.\n",
    "\n",
    "You can find help with the calibration and reconstruction functions on the site https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html\n",
    "\n",
    "## Goal\n",
    "\n",
    "In the zip of the statement you will find two sequences of images taken by two cameras during the scanning of an object by a laser plane.\n",
    "\n",
    "![Laser](scanRight/scan0010.png)\n",
    "\n",
    "You will also find shots of a checkerboard in different positions that will help you calibrate your cameras.\n",
    "\n",
    "![Damier](chessboards/c2Right.png)\n",
    "\n",
    "The goal is to reconstruct the scanned object in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 : calibration de la camera\n",
    "2 : par cette calibration, on peut récupérer les matrices de rotations et de translations correspondantes pour chaque image \n",
    "\n",
    "\n",
    "1 : trouver les matrices projections correspondantes des deux camera P et P' (par calibration de caméra) \n",
    "On a mis une ligne rouge sur l'objet avant de prendre des paires de photos (gauche et droite)\n",
    "2 : on peut determiner la matrice fondamentale a partir à partir de P et P', la matrice fondamentale F permet de trouver la ligne épipolaire (sur l'image de droite) correspondante à un point de l'image de gauche \n",
    "\n",
    "Avant de prendre les deux photos des cameras, on trace une ligne rouge sur l'objet qui va permettre de faciliter la correspondances entre un point et sa ligne épipolaire\n",
    "draw_epilines() dans open cv\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "def calibration():\n",
    "    # termination criteria\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((7*7,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:7,0:7].T.reshape(-1,2)\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    images = glob.glob('./chessboards/*.png')\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (7,7), None)\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv.cornerSubPix(gray,corners, (7,7), (-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            # Draw and display the corners\n",
    "            cv.drawChessboardCorners(img, (7,7), corners2, ret)\n",
    "            # cv.imshow('img', img)\n",
    "            # cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return ret,mtx,dist,rvecs,tvecs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamental\n",
      "[[ 7.46671675e+00 -3.11373946e+01 -2.64931378e+04]\n",
      " [ 3.53553100e+01  2.34629570e+00 -5.95894922e+04]\n",
      " [ 8.72536137e+03  5.53836121e+04  9.39038580e+06]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "mtx est la matrice intrinsèque de la camera -> Matrice 3x3\n",
    "rvecs : est un tuple d'array qui contient les composantes rotationnelles\n",
    "tvecs : idem mais pour translation\n",
    "\"\"\"\n",
    "\n",
    "ret,mtx,dist,rvecs,tvecs = calibration()\n",
    "\n",
    "\n",
    "def get_projection_matrix(i):\n",
    "    R = cv.Rodrigues(rvecs[i])[0]\n",
    "    t = tvecs[i]\n",
    "    Rt = np.concatenate([R,t], axis=-1) # [R|t] -> matrice de rotation\n",
    "    P = np.matmul(mtx,Rt) # A[R|t]\n",
    "    return P\n",
    "\n",
    "def get_camera_centre_matrix(i):\n",
    "    R = cv.Rodrigues(rvecs[i])[0]\n",
    "    t = tvecs[i]\n",
    "    #C = -R(eventuellement transposée) @ t\n",
    "    Rt = np.concatenate([R,t], axis=-1) # [R|t] -> matrice de rotation\n",
    "    C = -R@t # est une 3x1, on ajoute une quatrième composante qu'on fixe à 1 pour une caméra centrée dans le repère world\n",
    "    C = np.vstack([C,np.array([1])])\n",
    "    return C\n",
    "\"\"\"\n",
    "Create a dictionnary containning all interesting matrixes\n",
    "\"\"\"\n",
    "matrixes = dict()\n",
    "matrixes['mtx'] = mtx\n",
    "matrixes['rvecs'] = rvecs\n",
    "matrixes['tvecs'] = tvecs\n",
    "\n",
    "matrixes['P'],matrixes['C']= get_projection_matrix(0),get_camera_centre_matrix(0)\n",
    "matrixes[\"P'\"],matrixes[\"C'\"]= get_projection_matrix(1),get_camera_centre_matrix(1)\n",
    "matrixes[\"PseudoP\"] = np.linalg.pinv(matrixes['P'])\n",
    "# here we are only considerating the first set of 2 pictures\n",
    "\n",
    "\n",
    "def crossMat(vec):# doit retourner\n",
    "    x,y,z = vec\n",
    "    M = np.array([[0,-z[0],y[0]],\n",
    "                  [z[0],0,-x[0]],\n",
    "                  [-y[0],x[0],0]])\n",
    "    return M\n",
    "\n",
    "\"\"\"\n",
    "Compute first factor for Fundamental matrix\n",
    "\"\"\"\n",
    "First = matrixes[\"P'\"] @ matrixes['C']\n",
    "First = crossMat(First)\n",
    "\"\"\"\n",
    "Compute second factor for Fundamental matrix\n",
    "\"\"\"\n",
    "Second = matrixes[\"P'\"]@ matrixes['PseudoP']\n",
    "\"\"\"\n",
    "Matrice Fondamentale\n",
    "\"\"\"\n",
    "print(\"Fundamental\")\n",
    "F = First @Second\n",
    "print(F)\n",
    "\n",
    "\n",
    "# F = [P'C]x  P'  P+\n",
    "#     3x4 4x1 3x4 4x3\n",
    " \n",
    "#on a que l = F . x (l = ligne épipolaire, et x coordonnée du point image issue d'une image Left ou Right)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1497  440 1503  551]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def display_lines(img,lines):\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,255,0))\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('./scanLeft/0003.png')\n",
    "img = cv2.imread('./scanRight/scan0003.png')\n",
    "\n",
    "# Convert the image to the HSV color space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Set the lower and upper bounds for the red values\n",
    "lower_red = (0, 50, 50)\n",
    "upper_red = (10, 255, 255)\n",
    "\n",
    "# Create the mask using the cv2.inRange() function\n",
    "gray = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "lines = cv2.HoughLinesP(gray,1,np.pi/180,50,minLineLength=80,maxLineGap=300)\n",
    "# print(lines.shape) (6,1,4) on a dectecté 6 lignes , le 4 correspond aux quatres coordonnées x1,y1,x2,y2 \n",
    "lines = np.squeeze(lines)# pour retirer la dimension inutile\n",
    "\n",
    "\n",
    "display_lines(img,lines)\n",
    "\n",
    "print(lines[0])\n",
    "x1,y1,x2,y2 = lines[0]\n",
    "\n",
    "\n",
    "\n",
    "# Display the original and filtered images\n",
    "cv2.imshow('Original', img)\n",
    "# cv2.imshow('Filtered', gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7f8c0b8596b12b233065928e7df08b465f4de2b4476ac3f31d7d8adfffd429f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
